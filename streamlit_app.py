import streamlit as st
import os
import lancedb
from langchain.chains import create_retrieval_chain, create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import LanceDB
import uuid
from dotenv import load_dotenv

load_dotenv()
if "OPENAI_API_KEY" not in os.environ:
    raise ValueError("Please set OPENAI_API_KEY in .env file")

def initialize_components():
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    db = lancedb.connect("lancedb/hotels_rag_db")
    
    vectorstore = LanceDB(
        connection=db,
        embedding=embeddings,
        table_name="embeddings"
    )
    
    return vectorstore.as_retriever(), ChatOpenAI(model="gpt-4.1")

def create_rag_chain(retriever, llm):
    history_aware_prompt = ChatPromptTemplate.from_messages([
        ("system", 
         "–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –æ—Ç–µ–ª–µ–π –≤ —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–º –∞–≥–µ–Ω—Ç—Å—Ç–≤–µ. "
         "–ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–µ–Ω, –≤–Ω–∏–º–∞—Ç–µ–ª–µ–Ω –∫ –¥–µ—Ç–∞–ª—è–º –∏ –≤—Å–µ–≥–¥–∞ —Å—Ç—Ä–µ–º–∏—Å—å –ø—Ä–µ–≤–∑–æ–π—Ç–∏ –æ–∂–∏–¥–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞. "
         "–ò—Å–ø–æ–ª—å–∑—É–π –≤—Å—é –¥–æ—Å—Ç—É–ø–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞, —á—Ç–æ–±—ã –¥–µ–ª–∞—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ —Ç–æ—á–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. "
         "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø–æ–¥–æ–±—Ä–∞—Ç—å –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ –ª—É—á—à–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–µ–ª–µ–π, —É—á–∏—Ç—ã–≤–∞—è –µ–≥–æ –ø–æ–∂–µ–ª–∞–Ω–∏—è –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã. "
         "–ï—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –≤–µ–∂–ª–∏–≤–æ —É—Ç–æ—á–Ω–∏ –¥–µ—Ç–∞–ª–∏. "
         "–ü–æ–º–Ω–∏: –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å - –∑–∞–ª–æ–≥ —Ç–≤–æ–µ–π –≥–æ–¥–æ–≤–æ–π –ø—Ä–µ–º–∏–∏!"),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
        ("system", "–ù–∞—á–Ω–∏ –ø–æ–∏—Å–∫ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –æ—Ç–µ–ª–µ–π, —É—á–∏—Ç—ã–≤–∞—è –ø–æ–∂–µ–ª–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –∏ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞.")
    ])

    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", 
         "–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞ –æ –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–µ–ª–µ–π:\n"
         "{context}\n"
         "---\n"
         "–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞:\n"
         "{chat_history}\n"
         "–î–∞–π —á—ë—Ç–∫–∏–π, –ø–æ–ª–µ–∑–Ω—ã–π –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç, —Å—Å—ã–ª–∞—è—Å—å –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. "
         "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –≤–µ–∂–ª–∏–≤–æ —É—Ç–æ—á–Ω–∏ –¥–µ—Ç–∞–ª–∏ —É –∫–ª–∏–µ–Ω—Ç–∞."),
        ("human", "{input}"),
    ])

    history_aware_retriever = create_history_aware_retriever(
        llm, retriever, history_aware_prompt
    )
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    
    return create_retrieval_chain(history_aware_retriever, question_answer_chain)


#--------Streamlit UI------------

st.title("üè® –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

retriever, llm = initialize_components()
rag_chain = create_rag_chain(retriever, llm)

store = {}

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history",
    output_messages_key="answer",
)

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("–°–ø—Ä–æ—Å–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response = conversational_rag_chain.invoke(
            {"input": prompt},
            config={"configurable": {"session_id": st.session_state.session_id}}
        )
        answer = response["answer"]
        
        st.markdown(answer)
    
    st.session_state.messages.append({"role": "assistant", "content": answer})
